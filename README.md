# DynStaticNet: Dynamic-Static Dual-Branch Network for Multi-Weather Video Restoration

![License](https://img.shields.io/badge/license-MIT-green)

> ğŸ”¬ Official PyTorch implementation of **"DynStaticNet: Dynamic-Static Dual-Branch Network for Multi-Weather Video Restoration"**  
> [[Paper (Coming Soon)]](#) | [[Project Page]](#) | [[Video Demo]](#)

---

## ğŸŒŸ Overview

**DynStaticNet** is a biologically-inspired dual-branch framework for video restoration under complex and mixed weather conditions, such as rain, snow, and haze. It decouples spatial and temporal modeling to achieve efficient and accurate multi-weather restoration.

Key contributions include:

- ğŸ§  **Temporal Branch** with 3D Adaptive Self-Attention (3DASA) for modeling long-range motion.
- ğŸ‘ï¸ **Spatial Branch** with Multi-Gradient Aggregation Convolution (MGAConv) to enhance spatial detail extraction using directional gradients.
- ğŸ§© **Task-Adaptive Degradation Query** for generalization to unknown or mixed degradations without task labels.
- âš¡ **Efficient Design** reducing >70% FLOPs vs traditional attention-based models.

---

## ğŸ“ Project Structure

- `configs/` â€” YAML configs for training/testing  
- `data/` â€” Dataset loader and preprocessing scripts  
- `models/` â€” Model architecture: DynStaticNet, 3DASA, MGAConv  
- `scripts/` â€” Shell scripts for automation  
- `utils/` â€” Helper functions and tools  
- `pretrained/` â€” Pretrained checkpoints (download separately)  
- `main_train.py` â€” Training entry point  
- `main_eval.py` â€” Evaluation entry point  
- `README.md` â€” This file

---

## ğŸ Requirements

- Python 3.8+
- PyTorch â‰¥ 1.10
- CUDA â‰¥ 11.3
- torchvision
- numpy
- scikit-image
- tqdm
- pyyaml

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ Dataset Preparation

We reorganize three publicly available datasets into a unified **Multi-Weather Video Dataset (MWVD)**:

- ğŸŒ§ï¸ [RainSynAll100](https://github.com/lsy17096535/PRN)
- ğŸŒ«ï¸ [HazeWorld](https://github.com/volcanoscout/HazeWorld)
- â„ï¸ [RVSD (Snow)](https://github.com/chenyanglei/SnowFormer)

All videos are split into **10-frame clips**, and we ensure **no overlap** between training and test sets.

Expected directory structure:

- `data/MWVD/train/rain/` â€” 1000 clips  
- `data/MWVD/train/haze/` â€” 1000 clips  
- `data/MWVD/train/snow/` â€” 1000 clips  
- `data/MWVD/test/rain/` â€” 100 clips  
- `data/MWVD/test/haze/` â€” 100 clips  
- `data/MWVD/test/snow/` â€” 100 clips

To process and organize data:

```bash
bash scripts/prepare_dataset.sh
```

---

## ğŸš€ Training

To train DynStaticNet:

```bash
python main_train.py --config configs/train_dynstatic.yaml
```

To resume training from checkpoint:

```bash
python main_train.py --resume --checkpoint pretrained/latest.pth
```

---

## ğŸ“ˆ Evaluation

To evaluate a pretrained model:

```bash
python main_eval.py --config configs/eval.yaml --checkpoint pretrained/dynstaticnet.pth
```

---

## ğŸ§  Model Details

- **Embedding dimension**: 24  
- **3DASA attention heads**: [1, 2, 4]  
- **Blocks per stage**: [4, 6, 8]; refinement stage contains 4 blocks  
- **Batch size**: 4  
- **Each input**: 10 consecutive frames  
- **Input shape**: `[4, 10, 3, H, W]`  
- **Patch size**: 128 Ã— 128  
- **Augmentation**: Random rotation, horizontal flipping  
- **Optimizer**: Adam  
- **Learning rate**: Initial `2e-4`, decays to `1e-7` using cosine annealing

---

## ğŸ“Š Pretrained Models

| Model        | Dataset | PSNR (dB) | SSIM  | FLOPs (G) | Download |
|--------------|---------|-----------|-------|-----------|----------|
| DynStaticNet | MWVD    | 32.41     | 0.918 | 48.7      | [Coming Soon](#) |

---

## ğŸ§ª Ablation Results

| Variant | Spatial Branch | Convolution Type | PSNR â†‘ | SSIM â†‘ |
|---------|----------------|------------------|--------|--------|
| M1      | âŒ              | â€”                | XX.XX  | 0.XXX  |
| M2      | âœ…              | Vanilla Conv     | XX.XX  | 0.XXX  |
| M3      | âœ…              | MGAConv          | **XX.XX** | **0.XXX** |

---

## ğŸ’» Code Availability

We have released all source code, pretrained models, and dataset generation tools to support reproducibility.

ğŸ‘‰ **GitHub Repository**:  
[https://github.com/zqx1216155858/DynstaticNet](https://github.com/zqx1216155858/DynstaticNet)

---

## ğŸ“œ Citation

If you find our work helpful, please consider citing:

```bibtex
@article{your2024dynstaticnet,
  title={DynStaticNet: Dynamic-Static Dual-Branch Network for Multi-Weather Video Restoration},
  author={Your Name and Co-authors},
  journal={TBD},
  year={2024}
}
```

---

## ğŸ“¬ Contact

- ğŸ“§ Email: zqx1216155858@xxx.com  
- ğŸ› Issues: Please open an issue in this repository

Â© 2024 DynStaticNet Authors. Released under the [MIT License](LICENSE).
